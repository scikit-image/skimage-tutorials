{
 "metadata": {
  "kernelspec": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "name": "",
  "signature": "sha256:a613127582044b820d58261a18c9102573dfd6722dbb34c6608e586b1023d53a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Color and exposure"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "As discussed earlier, images are just numpy arrays. The numbers in those arrays correspond to the intensity of each pixel (or, in the case of a color image, the intensity of a specific color). To manipulate these, `scikit-image` provides the `color` and `exposure` modules."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Aside: Plotting images"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Before we get started, a quick note about plotting images---specifically, plotting gray-scale images with Matplotlib. First, let's grab an example image from `scikit-image`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage import data\n",
      "\n",
      "image = data.camera()"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Also, we'll want to make sure we have numpy and matplotlib imported."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "If we plot a gray-scale image using the default colormap, \"jet\", and a gray-scale color\n",
      "map, \"gray\", you can easily see the difference:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, (ax_jet, ax_gray) = plt.subplots(ncols=2)\n",
      "ax_jet.imshow(image, cmap='jet')\n",
      "ax_gray.imshow(image, cmap='gray');"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "We can get a better idea of the ill effects by zooming into the man's face."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "face = image[80:160, 200:280]\n",
      "fig, (ax_jet, ax_gray) = plt.subplots(ncols=2)\n",
      "ax_jet.imshow(face, cmap='jet')\n",
      "ax_gray.imshow(face, cmap='gray');"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice how the face looks distorted and splotchy with the \"jet\" colormap. Also, this colormap distorts the concepts of light and dark, and there are artificial boundaries created by the different color hues. Is that a beauty mark on the man's upper lip? No, it's just an artifact of this ridiculous colormap.\n",
      "\n",
      "Here's another example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, Y = np.ogrid[-5:5:0.1, -5:5:0.1]\n",
      "R = np.sqrt(X**2 + Y**2)\n",
      "\n",
      "fig, (ax_jet, ax_gray) = plt.subplots(1, 2)\n",
      "ax_jet.imshow(R, cmap='jet')\n",
      "ax_gray.imshow(R, cmap='gray');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Woah!  See all those non-existing contours?\n",
      "\n",
      "Setting the default colormap to 'gray' is recommended:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "plt.rcParams['image.cmap'] = 'gray'"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Don't worry: Color images are unaffected by this change.\n",
      "\n",
      "In addition, we'll set the interpolation to 'nearest neighborhood' so that it's easier to distinguish individual pixels in your image (the default is 'bicubic'--see the exploration below)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.rcParams['image.interpolation'] = 'nearest'"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can also set both of these explicitly in the ``imshow`` command:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(R, cmap='gray', interpolation='nearest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Interactive demo: interpolation and color maps"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.html.widgets import interact, fixed\n",
      "from matplotlib import cm as colormaps\n",
      "\n",
      "@interact(image=fixed(face),\n",
      "          cmap=sorted([c for c in colormaps.datad.keys() if not c.endswith('_r')],\n",
      "                      key=lambda x: x.lower()),\n",
      "          interpolation=['nearest', 'bilinear', 'bicubic',\n",
      "                         'spline16', 'spline36', 'hanning', 'hamming',\n",
      "                         'hermite', 'kaiser', 'quadric', 'catrom',\n",
      "                         'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos'])\n",
      "def imshow_params(image, cmap='jet', interpolation='bicubic'):\n",
      "    fig, axes = plt.subplots(1, 5, figsize=(15, 4))\n",
      "    \n",
      "    axes[0].imshow(image, cmap='gray', interpolation='nearest')\n",
      "    axes[0].set_title('Original')\n",
      "    \n",
      "    axes[1].imshow(image[:5, :5], cmap='gray', interpolation='nearest')\n",
      "    axes[1].set_title('Top 5x5 block')\n",
      "    axes[1].set_xlabel('No interpolation')\n",
      "\n",
      "    axes[2].imshow(image, cmap=cmap, interpolation=interpolation)\n",
      "    axes[2].set_title('%s colormap' % cmap)\n",
      "    axes[2].set_xlabel('%s interpolation' % interpolation)\n",
      "    \n",
      "    axes[3].imshow(image[:5, :5], cmap=cmap, interpolation=interpolation)\n",
      "    axes[3].set_title('%s colormap' % cmap)\n",
      "    axes[3].set_xlabel('%s interpolation' % interpolation)\n",
      "    \n",
      "    axes[4].imshow(R, cmap=cmap, interpolation=interpolation)\n",
      "    axes[4].set_title('%s colormap' % cmap)\n",
      "    axes[4].set_xlabel('%s interpolation' % interpolation)\n",
      "    \n",
      "    for ax in axes:\n",
      "        ax.set_xticks([])\n",
      "        ax.set_yticks([])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Color images have a 3rd dimension"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Color images are arrays with pixel rows and columns as the first two dimensions (just like a gray-scale image), plus a 3rd dimension that describes the RGB color channels:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "color_image = data.chelsea()\n",
      "plt.imshow(color_image);"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "color_image.shape"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Here we have an image with a height of 300 px, a width of 451 px, and 3 color channels, which are the red, green, and blue channels, in that order."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Basic array manipulation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Since images are just arrays, we can manipulate them as we would any other array."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Slicing and indexing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Let's say we want to plot just the red channel of the color image above. We know that the red channel is the first channel of the 3rd image-dimension. Since Python is zero-indexed, we can write the following:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "red_channel = color_image[:, :, 0]"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "But if we plot this image..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(red_channel);"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Obviously that's not red at all. The reason is that there's nothing to tell us that this array is supposed to be red: It's just a 2D array with a height, width, and intensity value---and no color information.\n",
      "\n",
      "The green channel is usually closest to the grey-scale version of the image.  Note that converting to grayscale cannot simply done by taking the mean of the three channels, since the eye is more sensitive to green than to red than to blue.  For that purpose, use ``skimage.color.rgb2gray``."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "red_channel.shape"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "The shape of this array is the same as it would be for any gray-scale image."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## <span class=\"exercize\">Exercise: three colours</span>\n",
      "\n",
      "Consider the following image (``images/balloon.jpg``):\n",
      "\n",
      "<img src=\"../images/balloon.jpg\"/>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Split this image up into its three components, red, green and blue, and display each separately.\n",
      "\n",
      "HINT: To display multiple images, we provide you with a small utility library called ``skdemo``:\n",
      "\n",
      "```python\n",
      "import skdemo\n",
      "skdemo.imshow_all()\n",
      "```\n",
      "\n",
      "Or, simply use ``matplotlib.subplots``:\n",
      "\n",
      "```python\n",
      "plt, axes = plt.subplots(1, 4)\n",
      "axes[0].imshow(...)\n",
      "axes[1].imshow(...)\n",
      "etc.\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage import io\n",
      "color_image = io.imread('../images/balloon.jpg')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import skdemo\n",
      "#skdemo.  # <TAB>"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This code is just a template to get you started.\n",
      "red_image = np.zeros_like(color_image)\n",
      "green_image = np.zeros_like(color_image)\n",
      "blue_image = np.zeros_like(color_image)\n",
      "\n",
      "skdemo.imshow_all(color_image, red_image, green_image, blue_image)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Combining color-slices with row/column-slices"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "In the examples above, we just manipulate the last axis of the array (i.e. the color channel). As with any NumPy array, however, slicing can be applied to each axis:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "color_patches = color_image.copy()\n",
      "# Remove green (1) & blue (2) from top-left corner.\n",
      "color_patches[:100, :100, 1:] = 0\n",
      "# Remove red (0) & blue (2) from bottom-right corner.\n",
      "color_patches[-100:, -100:, (0, 2)] = 0\n",
      "plt.imshow(color_patches);"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Histograms"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Histograms are a quick way to get a feel for the global statistics of the image intensity. For example, they can tell you where to set a threshold or how to adjust the contrast of an image."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "You might be inclined to plot a histogram using matplotlib's `hist` function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plt.hist(color_image)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "That didn't work as expected. How would you fix the call above to make it work correctly?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "<span class=\"exercize\">Counting pixels</span>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Create a function to **plot a histogram for each color channel** in a single plot."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Bonus: Instead of using `plt.hist`, use `plt.plot` or `plt.fill_between` in combination with `histogram` from `skimage.exposure`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Histograms of images"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "For this section, we're going to use a custom plotting function that adds a few tweaks to pretty-it-up:\n",
      "* Plot the image next to the histogram\n",
      "* Plot each RGB channel separately\n",
      "* Automatically flatten channels\n",
      "* Select reasonable bins based on the image's `dtype`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skdemo.imshow_with_histogram?"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Using this function, let's look at the histogram of a grayscale image:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "image = data.camera()\n",
      "skdemo.imshow_with_histogram(image);"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "An image histogram shows the number of pixels at each intensity value (or range of intensity values, if values are binned). Low-intensity values are closer to black, and high-intensity values are closer to white.\n",
      "\n",
      "Notice that there's a large peak at an intensity of about 10: This peak corresponds with the man's nearly black coat. The peak around the middle of the histogram is due to the predominantly gray tone of the image."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Now let's look at our color image:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cat = data.chelsea()\n",
      "skdemo.imshow_with_histogram(cat);"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "As you can see, the intensity for each RGB channel is plotted separately. Unlike the previous histogram, these histograms almost look like Gaussian distributions that are shifted. This reflects the fact that intensity changes are relatively gradual in this picture: There aren't very many uniform instensity regions in this image.\n",
      "\n",
      "An image with well-defined color regions gives a very different histogram:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skdemo.imshow_with_histogram(data.lena());"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "In this image, there are large patches of relatively uniform color, and these patches are often separated by sharp transitions. This results in multi-modal distributions and sharp transition regions. \n",
      "\n",
      "Note: These RGB histograms are pretty, but not that useful, since a high red value is very different if combined with low green and blue values (the result will tend toward red) vs high green and blue values (the result will tend toward white)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Histograms and contrast"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Enhancing the contrast of an image allow us to more easily identify features in an image, both by eye and by detection algorithms.\n",
      "\n",
      "Let's take another look at the gray-scale image from earlier:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "image = data.camera()\n",
      "skdemo.imshow_with_histogram(image);"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Notice the intensity values at the bottom. Since the image has a `dtype` of `uint8`, the values go from 0 to 255. Though you can see some pixels tail off toward 255, you can clearly see in the histogram, and in the image, that we're not using the high-intensity limits very well.\n",
      "\n",
      "Based on the histogram values, you might want to take all the pixels values that are more than about 180 in the image, and make them pure white (i.e. an intensity of 255). While we're at it, values less than about 10 can be set to pure black (i.e. 0). We can do this easily using `rescale_intensity`, from the `exposure` subpackage."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage import exposure\n",
      "high_contrast = exposure.rescale_intensity(image, in_range=(10, 180))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skdemo.imshow_with_histogram(high_contrast);"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "The contrast is visibly higher in the image, and the histogram is noticeably stretched. The sharp peak on the right is due to all the pixels greater than 180 (in the original image) that were piled into a single bin (i.e. 255)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exposure.rescale_intensity?"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Parameters for `rescale_intensity`:\n",
      "* `in_range`: The min and max intensity values desired in the input image. Values below/above these limits will be clipped.\n",
      "* `out_range`: The min and max intensity values of the output image. Pixels matching the limits from `in_range` will be rescaled to these limits. Everything in between gets linearly interpolated."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Histogram equalization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "In the previous example, the grayscale values (10, 180) were set to (0, 255), and everything in between was linearly interpolated. There are other strategies for contrast enhancement that try to be a bit more intelligent---notably histogram equalization.\n",
      "\n",
      "Let's first look at the cumulative distribution function (CDF) of the image intensities."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ax_image, ax_hist = skdemo.imshow_with_histogram(image)\n",
      "skdemo.plot_cdf(image, ax=ax_hist.twinx())"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "For each intensity value, the CDF gives the fraction of pixels *below* that intensity value.\n",
      "\n",
      "One measure of contrast is how evenly distributed intensity values are: The dark coat might contrast sharply with the background, but the tight distribution of pixels in the dark coat mean that details in the coat are hidden."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "To enhance contrast, we could *spread out intensities* that are tightly distributed and *combine intensities* which are used by only a few pixels."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "This redistribution is exactly what histogram equalization does. And the CDF is important because a perfectly uniform distribution gives a CDF that's a straight line. We can use `equalize_hist` from the `exposure` package to produce an equalized image:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "equalized = exposure.equalize_hist(image)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ax_image, ax_hist = skdemo.imshow_with_histogram(equalized)\n",
      "skdemo.plot_cdf(equalized, ax=ax_hist.twinx())"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "The tightly distributed dark-pixels in the coat have been spread out, which reveals many details in the coat that were missed earlier. As promised, this more even distribution produces a CDF that approximates a straight line.\n",
      "\n",
      "Notice that the image intensities switch from 0--255 to 0.0--1.0:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "equalized.dtype"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Functions in `scikit-image` allow any data-type as an input, but the output data-type may change depending on the algorithm. While `uint8` is really efficient in terms of storage, we'll see in the next section that computations using `uint8` images can be problematic in certain cases.\n",
      "\n",
      "If you need a specific data-type, check out the image conversion functions in scikit image:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import skimage\n",
      "\n",
      "#skimage.img_as  # <TAB>"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Contrasted-limited, adaptive histogram equalization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Unfortunately, histogram equalization tends to give an image whose contrast is artificially high. In addition, better enhancement can be achieved locally by looking at smaller patches of an image, rather than the whole image. In the image above, the contrast in the coat is much improved, but the contrast in the grass is somewhat reduced.\n",
      "\n",
      "Contrast-limited adaptive histogram equalization (CLAHE) addresses these issues. The implementation details aren't too important, but seeing the result is helpful:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "equalized = exposure.equalize_adapthist(image)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ax_image, ax_hist = skdemo.imshow_with_histogram(equalized)\n",
      "skdemo.plot_cdf(equalized, ax=ax_hist.twinx())"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Compared to plain-old histogram equalization, the high contrast in the coat is maintained, but the contrast in the grass is also improved. \n",
      "Furthermore, the contrast doesn't look overly-enhanced, as it did with the standard histogram equalization.\n",
      "\n",
      "Again, notice that the output data-type is different than our input. This time, we have a `uint16` image, which is another common format for images:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "equalized.dtype"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "There's a bit more tweaking involved in using `equalize_adapthist` than in `equalize_hist`: Input parameters are used to control the patch-size and contrast enhancement. You can learn more by checking out the docstring:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exposure.equalize_adapthist?"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Histograms and thresholding"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "One of the most common uses for image histograms is thresholding. Let's return to the original image and its histogram"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skdemo.imshow_with_histogram(image);"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Here the man and the tripod are fairly close to black, and the rest of the scene is mostly gray. But if you wanted to separate the two, how do you decide on a threshold value just based on the image? Looking at the histogram, it's pretty clear that a value of about 50 will separate the two large portions of this image."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 50"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ax_image, ax_hist = skdemo.imshow_with_histogram(image)\n",
      "# This is a bit of a hack that plots the thresholded image over the original.\n",
      "# This just allows us to reuse the layout defined in `plot_image_with_histogram`.\n",
      "ax_image.imshow(image > threshold)\n",
      "ax_hist.axvline(threshold, color='red');"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Note that the histogram plotted here is for the image *before* thresholding.\n",
      "\n",
      "This does a pretty good job of separating the man (and tripod) from most of the background. Thresholding is the simplest method of image segmentation; i.e. dividing an image into \"meaningful\" regions. More on that later.\n",
      "\n",
      "As you might expect, you don't have to look at a histogram to decide what a good threshold value is: There are (many) algorithms that can do it for you. For historical reasons, `scikit-image` puts these functions in the `filter` module.\n",
      "\n",
      "One of the most popular thresholding methods is Otsu's method, which gives a slightly different threshold than the one we defined above:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Rename module so we don't shadow the builtin function\n",
      "import skimage.filter as filters\n",
      "threshold = filters.threshold_otsu(image)\n",
      "print threshold"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(image > threshold);"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Note that the features of the man's face are slightly better resolved in this case.\n",
      "\n",
      "You can find a few other thresholding methods in the `filter` module:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import skimage.filter as filters\n",
      "filters.threshold  # <TAB>"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Color spaces"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "While RGB is fairly easy to understand, using it to detect a specific color (other than red, green, or blue) can be a pain. Other color spaces often devote a single component to the image intensity (a.k.a. luminance, lightness, or value) and two components to represent the color (e.g. hue and saturation in [HSL and HSV](http://en.wikipedia.org/wiki/HSL_and_HSV)).\n",
      "\n",
      "You can easily convert to a different color representation, or \"color space\", using functions in the `color` module."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage import color\n",
      "#color.rgb2  # <TAB>"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Here, we'll look at the LAB (a.k.a. CIELAB) color space (`L` = luminance, `a` and `b` define a 2D description of the actual color or \"hue\"):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from skimage import color\n",
      "\n",
      "lab_image = color.rgb2lab(color_image)\n",
      "lab_image.shape"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Converting to LAB didn't change the shape of the image at all. Let's try to plot it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(lab_image);"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Matplotlib expected an RGB array, and apparently, LAB arrays don't look anything like RGB arrays.\n",
      "\n",
      "That said, there is some resemblance to the original."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skdemo.imshow_all(lab_image[..., 0], lab_image[..., 1], lab_image[..., 2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "<span class=\"exercize\">Exploring color spaces</span>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "1. Decompose the Balloon image of earlier into its H, S and V color components.  Display each component and interpret the result.\n",
      "\n",
      "2. Use the CIELAB color space to **isolate the eyes** in the `chelsea` image. Plot the L, a, b components to get a feel for what they do, and see the [wikipedia page](http://en.wikipedia.org/wiki/Lab_colorspace) for more info. Bonus: **Isolate the nose** too."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## <span class=\"exercize\">Fun with film</span>\n",
      "\n",
      "In the film industry, it is often necessary to impose actors on top of a rendered background.  To do that, the actors are filmed on a \"green screen\".  Here's an example shot (``images/greenscreen.jpg``):\n",
      "\n",
      "<img src=\"../images/greenscreen.jpg\" width=\"300px\"/>\n",
      "\n",
      "Say we'd like to help these friendly folk travel into a rainforest (``images/forest.jpg``):\n",
      "\n",
      "<img src=\"../images/forest.jpg\" width=\"300px\"/>\n",
      "\n",
      "Can you help them by transplanting the foreground of the greenscreen onto the backdrop of the forest?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Further reading"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "* [Example of tinting gray-scale images](<http://scikit-image.org/docs/dev/auto_examples/plot_tinting_grayscale_images.html>)\n",
      "* Color spaces (see [`skimage.color`](http://scikit-image.org/docs/dev/api/skimage.color.html) package)\n",
      "  - `rgb2hsv`\n",
      "  - `rgb2luv`\n",
      "  - `rgb2xyz`\n",
      "  - `rgb2lab`\n",
      "* [Histogram equalization](http://scikit-image.org/docs/dev/auto_examples/plot_equalize.html) and [local histogram equalization](http://scikit-image.org/docs/dev/auto_examples/plot_local_equalize.html)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "\n",
      "<div style=\"height: 400px;\"></div>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%reload_ext load_style\n",
      "%load_style ../themes/tutorial.css"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        ".rendered_html {\n",
        "    font-family: Georgia, serif;\n",
        "    font-size: 130%;\n",
        "    line-height: 1.5;\n",
        "}\n",
        "\n",
        ".input {\n",
        "    width: 930px;\n",
        "}\n",
        "\n",
        ".inner_cell {\n",
        "    width: 800px;\n",
        "}\n",
        "\n",
        ".code_cell {\n",
        "    width: 800px;\n",
        "}\n",
        "\n",
        ".CodeMirror-sizer {\n",
        "}\n",
        "\n",
        "hr {\n",
        "    border: 1px solid #DDD;\n",
        "}\n",
        "\n",
        ".rendered_html h1 {\n",
        "    margin: 0.25em 0em 0.5em;\n",
        "    font-family: sans-serif;\n",
        "    color: #015C9C;\n",
        "    text-align: center;\n",
        "    line-height: 1.2;\n",
        "    page-break-before: always;\n",
        "}\n",
        "\n",
        ".rendered_html h2 {\n",
        "    margin: 1.1em 0em 0.5em;\n",
        "    font-family: sans-serif;\n",
        "    color: #26465D;\n",
        "    line-height: 1.2;\n",
        "}\n",
        "\n",
        ".rendered_html h3 {\n",
        "    font-family: sans-serif;\n",
        "    margin: 1.1em 0em 0.5em;\n",
        "    color: #002845;\n",
        "    line-height: 1.2;\n",
        "}\n",
        "\n",
        ".rendered_html li {\n",
        "    line-height: 1.5;\n",
        "}\n",
        "\n",
        ".CodeMirror-lines {\n",
        "    font-size: 110%;\n",
        "    line-height: 1.4em;\n",
        "    font-family: DejaVu Sans Mono, Consolas, Ubuntu, monospace;\n",
        "}\n",
        "\n",
        "h1.bigtitle {\n",
        "    margin: 4cm 1cm 4cm 1cm;\n",
        "    font-size: 300%;\n",
        "}\n",
        "\n",
        "h3.point {\n",
        "    font-size: 200%;\n",
        "    text-align: center;\n",
        "    margin: 2em 0em 2em 0em;\n",
        "    #26465D\n",
        "}\n",
        "\n",
        ".logo {\n",
        "    margin: 20px 0 20px 0;\n",
        "}\n",
        "\n",
        "a.anchor-link {\n",
        "    display: none;\n",
        "}\n",
        "\n",
        "h1.title {\n",
        "    font-size: 250%;\n",
        "}\n",
        "\n",
        ".exercize {\n",
        "    color: #738;\n",
        "}\n",
        "\n",
        "h2 .exercize {\n",
        "    font-style: italic;\n",
        "}\n",
        "\n",
        "</style>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x7feb2e898438>"
       ]
      }
     ],
     "prompt_number": 11
    }
   ],
   "metadata": {}
  }
 ]
}